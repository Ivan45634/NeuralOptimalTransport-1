{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "\n",
    "from src import distributions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.resnet2 import ResNet_D\n",
    "from src.unet import UNet\n",
    "\n",
    "from src.tools import unfreeze, freeze\n",
    "from src.tools import load_dataset, get_Z_pushed_loader_stats\n",
    "from src.fid_score import calculate_frechet_distance\n",
    "from src.tools import weights_init_D\n",
    "from src.plotters import plot_random_Z_images, plot_Z_images\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb\n",
    "from src.tools import fig2data, fig2img # for wandb\n",
    "\n",
    "# This needed to use dataloaders for some datasets\n",
    "from PIL import PngImagePlugin\n",
    "LARGE_ENOUGH_NUMBER = 100\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/gpfs0/groznyy.sergey/listopadov_i/NeuralOptimalTransport/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DEVICE_IDS = [0,1]\n",
    "\n",
    "DATASET1, DATASET1_PATH = 'animals', '/gpfs/gpfs0/groznyy.sergey/listopadov_i/all_downsampling_animals/train'\n",
    "DATASET2, DATASET2_PATH = 'pokemons', '/gpfs/gpfs0/groznyy.sergey/listopadov_i/downsampling_pokemons/train'\n",
    "\n",
    "# DATASET1, DATASET1_PATH = 'celeba_female', '../../data/img_align_celeba'\n",
    "# DATASET2, DATASET2_PATH = 'aligned_anime_faces', '../../data/aligned_anime_faces'\n",
    "\n",
    "T_ITERS = 10\n",
    "f_LR, T_LR = 1e-4, 1e-4\n",
    "IMG_SIZE = 32\n",
    "\n",
    "ZC = 1\n",
    "Z_STD = 0.1\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "Z_SIZE = 8\n",
    "\n",
    "PLOT_INTERVAL = 100\n",
    "COST = 'weak_mse'\n",
    "CPKT_INTERVAL = 2000\n",
    "MAX_STEPS = 100001\n",
    "SEED = 0x000000\n",
    "\n",
    "# Gamma will linearly increase from 0 to 0.66 during first 25k iters of the potential\n",
    "GAMMA0, GAMMA1 = 0.0, 0.66\n",
    "GAMMA_ITERS = 25000\n",
    "\n",
    "EXP_NAME = f'{DATASET1}_{DATASET2}_T{T_ITERS}_{COST}_{IMG_SIZE}'\n",
    "OUTPUT_PATH = '../checkpoints/{}/{}_{}_{}/'.format(COST, DATASET1, DATASET2, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    DATASET1=DATASET1,\n",
    "    DATASET2=DATASET2, \n",
    "    T_ITERS=T_ITERS,\n",
    "    f_LR=f_LR, T_LR=T_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE\n",
    ")\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_IDS[0]}')\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir '/gpfs/gpfs0/groznyy.sergey/listopadov_i/downsampling_pokemons/stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch '/gpfs/gpfs0/groznyy.sergey/listopadov_i/downsampling_pokemons/stats/{}_{}_test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/gpfs/gpfs0/groznyy.sergey/listopadov_i/downsampling_pokemons/stats/pokemons_32_test.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/gpfs/gpfs0/groznyy.sergey/listopadov_i/downsampling_pokemons/stats/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_test.json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(DATASET2, IMG_SIZE)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m      3\u001b[0m     data_stats \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fp)\n\u001b[1;32m      4\u001b[0m     mu_data, sigma_data \u001b[38;5;241m=\u001b[39m data_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmu\u001b[39m\u001b[38;5;124m'\u001b[39m], data_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gpfs/gpfs0/groznyy.sergey/listopadov_i/downsampling_pokemons/stats/pokemons_32_test.json'"
     ]
    }
   ],
   "source": [
    "filename = '/gpfs/gpfs0/groznyy.sergey/listopadov_i/downsampling_pokemons/stats/{}_{}_test.json'.format(DATASET2, IMG_SIZE)\n",
    "with open(filename, 'r') as fp:\n",
    "    data_stats = json.load(fp)\n",
    "    mu_data, sigma_data = data_stats['mu'], data_stats['sigma']\n",
    "del data_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Samplers (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampler, X_test_sampler = load_dataset(DATASET1, DATASET1_PATH, img_size=IMG_SIZE)\n",
    "Y_sampler, Y_test_sampler = load_dataset(DATASET2, DATASET2_PATH, img_size=IMG_SIZE)\n",
    "    \n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ResNet_D(IMG_SIZE, nc=3).cuda()\n",
    "f.apply(weights_init_D)\n",
    "\n",
    "T = UNet(3+ZC, 3, base_factor=48).cuda() # ZC - noise input channels z\n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
    "    f = nn.DataParallel(f, device_ids=DEVICE_IDS)\n",
    "    \n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "print('f params:', np.sum([np.prod(p.shape) for p in f.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "X_fixed = X_sampler.sample(10)[:,None].repeat(1,4,1,1,1)\n",
    "with torch.no_grad():\n",
    "    Z_fixed = torch.randn(10, 4, ZC, IMG_SIZE, IMG_SIZE, device='cuda') * Z_STD\n",
    "    XZ_fixed = torch.cat([X_fixed, Z_fixed], dim=2)\n",
    "del X_fixed, Z_fixed\n",
    "Y_fixed = Y_sampler.sample(10)\n",
    "\n",
    "X_test_fixed = X_test_sampler.sample(10)[:,None].repeat(1,4,1,1,1)\n",
    "with torch.no_grad():\n",
    "    Z_test_fixed = torch.randn(10, 4, ZC, IMG_SIZE, IMG_SIZE, device='cuda') * Z_STD\n",
    "    XZ_test_fixed = torch.cat([X_test_fixed, Z_test_fixed], dim=2)\n",
    "del X_test_fixed, Z_test_fixed\n",
    "Y_test_fixed = Y_test_sampler.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plot_Z_images(XZ_fixed, Y_fixed, T)\n",
    "fig, axes = plot_random_Z_images(X_sampler, ZC, Z_STD, Y_sampler, T)\n",
    "fig, axes = plot_Z_images(XZ_test_fixed, Y_test_fixed, T)\n",
    "fig, axes = plot_random_Z_images(X_test_sampler, ZC, Z_STD, Y_test_sampler, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, project='notreallyweakot', entity='gunsandroses', config=config)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "f_opt = torch.optim.Adam(f.parameters(), lr=f_LR, weight_decay=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm(range(MAX_STEPS)):\n",
    "    gamma = min(GAMMA1, GAMMA0 + (GAMMA1-GAMMA0) * step / GAMMA_ITERS)\n",
    "    # T optimization\n",
    "    unfreeze(T); freeze(f)\n",
    "    for t_iter in range(T_ITERS): \n",
    "        T_opt.zero_grad()\n",
    "        X = X_sampler.sample(BATCH_SIZE)[:,None].repeat(1,Z_SIZE,1,1,1)\n",
    "        with torch.no_grad():\n",
    "            Z = torch.randn(BATCH_SIZE, Z_SIZE, ZC, IMG_SIZE, IMG_SIZE, device='cuda') * Z_STD\n",
    "            XZ = torch.cat([X, Z], dim=2)\n",
    "        T_XZ = T(\n",
    "            XZ.flatten(start_dim=0, end_dim=1)\n",
    "        ).permute(1,2,3,0).reshape(3, IMG_SIZE, IMG_SIZE, -1, Z_SIZE).permute(3,4,0,1,2)\n",
    "        \n",
    "        T_loss = F.mse_loss(X[:,0], T_XZ.mean(dim=1)).mean() - \\\n",
    "        f(T_XZ.flatten(start_dim=0, end_dim=1)).mean() + \\\n",
    "        T_XZ.var(dim=1).mean() * (1 - gamma - 1. / Z_SIZE)\n",
    "        \n",
    "        T_loss.backward(); T_opt.step()\n",
    "    del T_loss, T_XZ, X, Z; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    # f optimization\n",
    "    freeze(T); unfreeze(f)\n",
    "    X = X_sampler.sample(BATCH_SIZE)\n",
    "    with torch.no_grad():\n",
    "        Z = torch.randn(BATCH_SIZE, ZC, X.size(2), X.size(3), device='cuda') * Z_STD\n",
    "        XZ = torch.cat([X,Z], dim=1)\n",
    "        T_XZ = T(XZ)\n",
    "    Y = Y_sampler.sample(BATCH_SIZE)\n",
    "    f_opt.zero_grad()\n",
    "    f_loss = f(T_XZ).mean() - f(Y).mean()\n",
    "    f_loss.backward(); f_opt.step();\n",
    "    wandb.log({f'f_loss' : f_loss.item()}, step=step)\n",
    "    del f_loss, Y, X, T_XZ, Z, XZ; gc.collect(); torch.cuda.empty_cache()\n",
    "        \n",
    "    if step % PLOT_INTERVAL == 0:\n",
    "        print('Plotting')\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        fig, axes = plot_Z_images(XZ_fixed, Y_fixed, T)\n",
    "        wandb.log({'Fixed Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_Z_images(X_sampler, ZC, Z_STD,  Y_sampler, T)\n",
    "        wandb.log({'Random Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_Z_images(XZ_test_fixed, Y_test_fixed, T)\n",
    "        wandb.log({'Fixed Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_Z_images(X_test_sampler, ZC, Z_STD,  Y_test_sampler, T)\n",
    "        wandb.log({'Random Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "    \n",
    "    if step % CPKT_INTERVAL == CPKT_INTERVAL - 1:\n",
    "        freeze(T); \n",
    "        \n",
    "        print('Computing FID')\n",
    "        mu, sigma = get_Z_pushed_loader_stats(T, X_test_sampler.loader, ZC=ZC, Z_STD=Z_STD)\n",
    "        fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
    "        wandb.log({f'FID (Test)' : fid}, step=step)\n",
    "        del mu, sigma\n",
    "        \n",
    "        torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f'T_{SEED}_{step}.pt'))\n",
    "#         torch.save(f.state_dict(), os.path.join(OUTPUT_PATH, f'f_{SEED}_{step}.pt'))\n",
    "#         torch.save(f_opt.state_dict(), os.path.join(OUTPUT_PATH, f'f_opt_{SEED}_{step}.pt'))\n",
    "#         torch.save(T_opt.state_dict(), os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{step}.pt'))\n",
    "    \n",
    "    gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
